\subsection{Direct and indirect methods}
Since we can transform the problem of optimal control into a two-point 
boundary ODE problem, the methods designed for this sort of problem are 
applicable see \cite{Keller1976, Ascher1987, Stoer2013} for classic references. 
In this line \cite{Caetano2001,Yan2008} use multiple shooting methods to 
solve the resulting extended two-value boundary ODE.

{\it Multiple shooting method}
Consider the controlled dynamics and corresponding adjoint equations given by
\begin{equation}
  \label{eqn:extended_tpvbp}
  \begin{aligned}
    \dot{x}(t) &= 
    f(x(t), u(t)), \qquad x(0)=x_0 \\
    \dot{\lambda}(t) &=
    -\mathcal{H}_x(x(t),u(t),\lambda(t))^\top, \quad 
    \lambda(T)=0.
  \end{aligned}
\end{equation}
Roughly speaking, the multiple shooting method follows the next algorithm.
Given a partition of the interval $[0, T]$ with uniform step $h$,
$$
\tau_h^n:= \{t_k = kh, \ k=0,\dots n\},
$$
the multi shooting method is described in \Cref{alg:multishooting}.
\begin{algorithm}
  \caption{Multi shooting method } \label{alg:multishooting}
  \begin{flushleft}
    \hspace*{\algorithmicindent} \textbf{Input:} 
    $t_0, T, x_0, h, \text{tol}, \lambda_{f}, n_{max}$ \\
    \hspace*{\algorithmicindent} \textbf{Output:} 
    $x^*, u^*, \lambda$
  \end{flushleft}
  \begin{algorithmic}
    \Procedure{Multi\_shooting}{$g,\lambda_{\text{function}}, 
      u, x_0, 
      \lambda_f, h, n_{max}$} 
      \While{$ \epsilon > \text{tol}  $}
        \State 
         Choose $y_i := [x(t_i ), \lambda(t_i )], \quad i = 1,\dots, n$.
        \\
        \State 
          Integrate \eqref{eqn:extended_tpvbp} for each sub-interval 
          $[t_i , t_{i+1})$ using $y_i$ as the initial conditions 
          \\
          \hspace{.98cm}
          and obtain 
          $y(t_{i−1}) = [x(t_{i−1}), \lambda(t_{i−1})]$, 
          $i=2, \dots, n$.
        \\
        \State 
          $\mathcal{Y} \gets [y_i - y(t_i)]$, $i=0, \dots, n$
        \State
          Actualize initial condition $y_i$ for next iteration
          using for a example a
          \\
          \hspace{.98cm}
           Newton's method.
        \State
          $\epsilon \gets |\mathcal{Y}|$  
      \EndWhile
     \EndProcedure
  \end{algorithmic}
\end{algorithm}


  However, the {\it forward-backward-sweep method} is the most popular method in 
works on optimal control epidemic models, perhaps for its simple 
implementation and acceptable convergence. All simulations presented in this work runs with 
this scheme. \citet{hackbusch1978numerical} propose this numerical scheme to 
solve a class of optimal problems that encloses the models of Section 3.
\citet{lenhart2007optimal} provides MATLAB code for many of its regarding
work in biological models.

\begin{algorithm}
  \caption{Forward Backward Sweep } \label{alg:forward_backward_sweep}
  \begin{flushleft}
    \hspace*{\algorithmicindent} \textbf{Input:} 
    $t_0, t_f, x_0,h, \text{tol}, \lambda_{f}$ \\
    \hspace*{\algorithmicindent} \textbf{Output:} 
    $x^*, u^*, \lambda$
  \end{flushleft}
  \begin{algorithmic}
    \Procedure{Forward\_backward\_sweep}{$g,\lambda_{\text{function}}, 
      u, x_0, 
      \lambda_f, h, n_{max}$} 
    \While{$ \epsilon > \text{tol}  $}
      \State $u_{\text{old}} \gets u$ 
      \State $x_{\text{old}} \gets x$ 
      \State $ x \gets$
      \State $\lambda_{\text{old}} \gets \lambda $
      \Call{runge\_kutta\_forward}{$g, u, x_0, h$}
      \State $\lambda \gets$ 
        \Call{runge\_kutta\_backward}{%
       $\lambda_{\text{function}}, x, \lambda_f, h$}
      \State $u_1 \gets$ 
        \Call{optimality\_condition}{$u, x, \lambda$}
    %
      \State 
        $u \gets \alpha u_1 + (1-\alpha)u_{old}, 
        \qquad \alpha \in [0, 1]$
        \Comment{convex combination}
      \State 
      $\epsilon_u \gets \displaystyle 
        \frac{||u - u_{\text{old}}||}{||u||}$
      \State 
      $\epsilon_x \gets \displaystyle 
        \frac{||x - x_{\text{old}}||}{||x||}$
      \Comment{relative error}
      \State 
        $\epsilon_{\lambda} \gets \displaystyle 
        \frac{||\lambda - \lambda_{\text{old}}||}{||\lambda||}$
      \State 
        $\epsilon \gets 
        \max{ 
          \{ \epsilon_u, \epsilon_x, \epsilon_{\lambda} \}
       }$
    \EndWhile\label{}
      \State \textbf{return} $ x^*, u^*, \lambda$
        \Comment{Optimal pair}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\medskip  
\subsection{Evolutionary algorithms}
Evolutionary algorithms are a kind of heuristic algorithms well 
suited for global optimization. Such algorithms emulate natural
evolution introducing operators for mutation ($\mathbf{M}$), crossover 
($\mathbf{C}$) and selection ($\mathbf{S}$). One of the earliest works on
evolutionary methods was developed by George E. 
P. Box \cite{Box1957}. Nevertheless, it can be said that the first evolutionary 
algorithm at least as they are known today, was the so called Genetic Algorithm 
(GA) introduced by \citet{JHH1975}. Many variations of
evolutionary algorithms have been developed being Differential Evolution (DE),
introduced by \citet{Storn1997}, one of the simplest yet 
efficient and effective optimization algorithms. Algorithm \ref{alg:DE1} shows 
the general form of Evolutionary Algorithms for optimizing the  
objective function $fob$. There, an initial population $Y$ of size $N_p$, 
generated in the search space $\mathcal{V}$ by the operator $\mathbf{Y}_0$,
is subject to the evolutionary process until certain stopping criterion is 
met. Then the best individual ($\mathbf{y}_{best}$), i.e., the individual who
optimizes $fob$, is selected by introducing the operator $\mathbf{Best}$. 
In Algorithm \ref{alg:DE1} the variable $M$ stores a mutated population, 
the variable $C$ stores the results of the crossover operator. The selection
operator selects from $C$ and $Y$ the individuals which will conform the new
generation of individuals of $Y$. This selection is based in some criteria 
usually dictated by the objective function. For instance, if $\mathbf{y}$ is an 
element of $Y$ and $\mathbf{c}$ an element of $C$, a common criterion for 
minimization is to select $\mathbf{y}$ if $fob(\mathbf{y})<fob(\mathbf{c})$.
A detailed explanation for constructing the main operators 
$\mathbf{M}$, $\mathbf{C}$ and $\mathbf{S}$, can be found in
\cite{Bagchi1999} for GA and in \cite{Price_Storn2005} for the DE
algorithm.
%
\begin{algorithm}[htb]
  \caption{Evolutionary Algorithms}
  \label{alg:DE1}
  \begin{algorithmic}
    % \small
    \State $Y$ $\leftarrow$ $\mathbf{Y}_0(Np,\mathcal{V})$
    \While{(the stopping criterion has not been met)}
    \State $M$ $\leftarrow$  $\mathbf{M}(Y)$
    \State $C$ $\leftarrow$  $\mathbf{C}(Y,C)$
    \State $Y$ $\leftarrow$  $\mathbf{S}(Y,C,fob)$ 
    \EndWhile
    \State $\mathbf{y}_{best} \leftarrow \mathbf{Best}(Y, fob)$
  \end{algorithmic}
\end{algorithm}%

  Regarding the optimal control policies problem, authors frequently apply the 
evolutionary method by using piecewise constant functions for the controllers 
$u_k$, $k=1,2,\dots,n$. For instance, the optimization of a
quantity of the form
\begin{equation}
  J(u_1,u_2,\dots,u_n) = \int_0^T{\left[ \mathcal{L}(t) + w_1\,u_1^2(t) + 
  w_2\,u_2^2(t)+\dots + w_n\,u_n^2(t) \right]\,dt},
\label{eq:Jaccion}
\end{equation}
with weight constants $w_k$, can be conducted by discretizing the 
interval $I = [0,T]$ in disjoint subintervals $I_j$ and choosing  
\begin{equation}\label{DECrossover}
  u_{k}(t) =
  \begin{cases}
    u^j_{k} & \text{if $t \in I_j$}
      \vspace*{0.1cm}\\
      0 & \text{otherwise.}
  \end{cases}
\end{equation}
  Usually the functional under the sign of integral in \Cref{eq:Jaccion}
obeys a specific dynamical model which needs to be solved but in such a way
that $J$ is optimized. Now, the numbers $u^j_{k}$ will be part of an 
individual who will be subject to the evolutionary process. 
\citet{Yan2008,Jang2018} follows this approach respectively for the GA and the 
DE algorithms.